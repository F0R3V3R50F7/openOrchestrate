<div align="center">

# ğŸ® openOrchestrate ğŸ®

### â–‘â–‘â–‘â–’â–’â–’â–“â–“â–“ LOCAL AI, TREATED WITH RESPECT â–“â–“â–“â–’â–’â–’â–‘â–‘â–‘

</div>

---

<div align="center">

![Visitors](https://img.shields.io/badge/visitors-âˆ-blue?style=for-the-badge&logo=lighthouse)
![Status](https://img.shields.io/badge/status-ONLINE-00ff00?style=for-the-badge&logo=statuspage)
![AI](https://img.shields.io/badge/100%25-LOCAL_AI-ff00ff?style=for-the-badge)
![No Cloud](https://img.shields.io/badge/â˜ï¸_CLOUD-FORBIDDEN-red?style=for-the-badge)

**Est. 2024** | **Powered by llama.cpp** | **Built on Caffeine & Principles**

</div>

---

<table width="100%">
<tr>
<td width="50%" valign="top">

### ğŸ“° **LATEST HEADLINES**

```
[BREAKING] Local AI Finally Gets
           Proper Orchestration!
           
[NEW!] Context Windows That Don't
       Silently Fail You
       
[HOT!] VRAM Constraints? We Actually
       Respect Those Here
```

</td>
<td width="50%" valign="top">

### ğŸ¯ **QUICK STATS**

```
Lines of Code.... 313,000+ chars
Models Supported. UNLIMITED*
Cloud Deps....... 0
Telemetry........ 0
Working Paths.... SACRED
```
<sub>*if llama.cpp supports it</sub>

</td>
</tr>
</table>

---

## ğŸŒŸ â–‚â–ƒâ–…â–‡â–ˆ WELCOME TO THE PORTAL â–ˆâ–‡â–…â–ƒâ–‚ ğŸŒŸ

**Greetings, traveler.** You've discovered a sanctuary where local AI is treated with the dignity it deserves.

This isn't your typical GitHub repo. This is **openOrchestrate** â€” a rebellion against:
- âŒ Silent context amnesia
- âŒ VRAM assumptions from fantasyland  
- âŒ Breaking changes disguised as "features"
- âŒ Cloud dependencies for "convenience"

We believe local AI should behave like **well-engineered systems**, not fragile tech demos held together with duct tape and prayers.

---

<div align="center">

### âœ¨ _Â«Â« You are entering a NO-BS ZONE Â»Â»_ âœ¨

</div>

---

## ğŸ® MAIN MENU

<table>
<tr>
<td width="33%" align="center">

### [ğŸ  HOME]

**What Is This?**

A complete **Local-First MoE AI Front-End** built with phpDesktop-Chrome and llama.cpp.

Not just a chat UI.  
An orchestration layer.

</td>
<td width="33%" align="center">

### [âš¡ FEATURES]

**Core Systems**

â†’ Intelligent routing  
â†’ Long-term memory  
â†’ Context pruning  
â†’ Multi-model exec  
â†’ 100% local  

</td>
<td width="33%" align="center">

### [ğŸ”§ TECH]

**Stack Info**

PHP backend  
JS frontend  
llama.cpp engine  
Zero frameworks  
Zero bloat  

</td>
</tr>
</table>

---

## ğŸª THE MAIN EVENT: Features That Actually Matterâ„¢

### ğŸ§  **INTELLIGENT MODEL ROUTING**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Query: "Write me a Python script"     â•‘
â•‘  â–¼                                     â•‘
â•‘  Router: *routes to CODE EXPERT*       â•‘
â•‘  â–¼                                     â•‘
â•‘  Result: Actually good code âœ“          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```
Queries auto-route to specialized models: **general**, **code**, **medical**.  
No more asking your general model to write regex. It was suffering.

---

### ğŸ’¾ **VELOCITY INDEX** (a.k.a. Long-Term Memory That Works)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OLD APPROACH:                       â”‚
â”‚ Context full â†’ DELETE EVERYTHING    â”‚
â”‚              â†’ Start over           â”‚
â”‚              â†’ Model: "who are you?"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VELOCITY INDEX:                     â”‚
â”‚ Context full â†’ ARCHIVE & INDEX      â”‚
â”‚              â†’ Recall when needed   â”‚
â”‚              â†’ Continuity preserved â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
Your AI remembers things. Revolutionary, we know.

---

### âœ‚ï¸ **CONTEXT PRUNING** (Not Context Amnesia)
```
 Before:  [Msg1][Msg2][Msg3][Msg4][Msg5][Msg6]...
             â–¼
 Limit:   PANIC! DELETE RANDOMLY!
             â–¼
 After:   [Msg4][Msg5][Msg6] (what was Msg1-3? Â¯\_(ãƒ„)_/Â¯)
```

**VS**

```
 Before:  [Msg1][Msg2][Msg3][Msg4][Msg5][Msg6]...
             â–¼
 Limit:   CONDENSE INTELLIGENTLY
             â–¼
 After:   [Summary of 1-3][Msg4][Msg5][Msg6]
```

Context limits managed **deliberately**, not accidentally.

---

### ğŸ›ï¸ **MULTI-MODEL EXECUTION**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  GPU: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 80% allocated     â•‘
â•‘  CPU: [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] Auxiliary model   â•‘
â•‘                                      â•‘
â•‘  General Model: LOADED (GPU)         â•‘
â•‘  Code Model:    LOADED (GPU)         â•‘
â•‘  Helper Model:  LOADED (CPU)         â•‘
â•‘                                      â•‘
â•‘  VRAM: Predictable âœ“                 â•‘
â•‘  System: Stable âœ“                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```
Run multiple GGUF models simultaneously. Designed for **real hardware**.

---

### ğŸ”’ **LOCAL-ONLY BY DESIGN**
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ  No API calls                      â”ƒ
â”ƒ  No telemetry                      â”ƒ
â”ƒ  No cloud dependencies             â”ƒ
â”ƒ  No background services            â”ƒ
â”ƒ  No "anonymous usage data"         â”ƒ
â”ƒ  No "just this once" exceptions    â”ƒ
â”ƒ                                    â”ƒ
â”ƒ  EVERYTHING STAYS ON YOUR MACHINE  â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
```

---

### ğŸ“ **FILE ATTACHMENTS**
Attach text files directly. Analyze, summarize, reference.  
Fully local. As it should be.

---

## ğŸ—ï¸ ARCHITECTURE: The Boring Parts (That Work)

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   USER INTERFACE                    â”‚
â”‚            (HTML/CSS/JS - No Frameworks)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PIPELINE ENGINE                     â”‚
â”‚         Multi-stage request processing              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼           â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LLAMA  â”‚  â”‚VELOCITYâ”‚  â”‚ CONTEXT  â”‚
    â”‚GOVERNORâ”‚  â”‚ INDEX  â”‚  â”‚ PRUNING  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   llama.cpp     â”‚
    â”‚ (Inference Eng) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

### ğŸ¯ **TECH STACK**

| Component | Tech | Why |
|-----------|------|-----|
| Frontend | HTML/CSS/JS | ~66k chars of styles, zero frameworks, zero bloat |
| Backend | PHP | ~40k chars of logic that actually works |
| Runtime | phpDesktop-Chrome | Native desktop, no Electron nonsense |
| Inference | llama.cpp | Battle-tested, community-proven |

**Total Codebase:** 313,000+ characters of disciplined engineering.

---

### ğŸ¨ **CORE SUBSYSTEMS**

<table>
<tr>
<td width="33%">

#### ğŸ”„ Pipeline Engine
Multi-stage processing with clear separation of concerns.

No spaghetti. No magic. No "it just works" handwaving.

</td>
<td width="33%">

#### ğŸ‘‘ Llama Governor
Central authority for model lifecycle, routing, and resource limits.

One ruler. Clear laws. Predictable behavior.

</td>
<td width="33%">

#### ğŸš€ Velocity Index
Long-term memory system for recall and reconstruction.

Because forgetting everything is not a feature.

</td>
</tr>
</table>

---

## ğŸ­ SUPPORTED MODELS

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  IF llama.cpp CAN RUN IT, WE CAN ORCHESTRATE IT  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

<table width="100%">
<tr>
<td valign="top" width="50%">

**ğŸ—£ï¸ GENERAL LLMs**
- Llama 2/3
- Mistral
- Qwen
- Gemma
- Your custom GGUF

</td>
<td valign="top" width="50%">

**ğŸ’» CODE MODELS**
- CodeLlama
- DeepSeek-Coder
- StarCoder
- WizardCoder

</td>
</tr>
<tr>
<td valign="top">

**ğŸ¥ MEDICAL/RESEARCH**
- Meditron
- BioMistral
- Clinical models

</td>
<td valign="top">

**ğŸ”§ CUSTOM EXPERTS**
- Fully configurable
- No hardcoded assumptions
- Your rules, your models

</td>
</tr>
</table>

---

## ğŸ² DESIGN PHILOSOPHY

<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                       â•‘
â•‘  âš¡ Constraints are real                             â•‘
â•‘  âš¡ Regression is failure                            â•‘
â•‘  âš¡ Working paths are sacred                         â•‘
â•‘  âš¡ Frontends are part of the intelligence           â•‘
â•‘  âš¡ Graceful degradation beats silent failure        â•‘
â•‘                                                       â•‘
â•‘  IF A FEATURE BREAKS AN INVARIANT, IT DOES NOT SHIP  â•‘
â•‘                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

</div>

---

<table width="100%">
<tr>
<td width="50%" bgcolor="#000000">

### âš ï¸ WHAT WE DON'T DO

```
âœ— Assume infinite VRAM
âœ— Discard context silently
âœ— Break working paths
âœ— Ship features over stability
âœ— Pretend constraints don't exist
âœ— Require cloud services
âœ— Collect telemetry
âœ— Make excuses
```

</td>
<td width="50%" bgcolor="#001100">

### âœ… WHAT WE DO

```
âœ“ Respect your hardware
âœ“ Manage context deliberately
âœ“ Preserve working behavior
âœ“ Ship stable releases
âœ“ Embrace reality
âœ“ Stay 100% local
âœ“ Respect your privacy
âœ“ Deliver results
```

</td>
</tr>
</table>

---

## ğŸ“Š PROJECT STATUS

<div align="center">

### ğŸš§ **UNDER ACTIVE DEVELOPMENT** ğŸš§

</div>

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Focus: Stability > Features            â”‚
â”‚ Priority: Coherence > Speed            â”‚
â”‚ Approach: Conservative > Flashy        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What to expect:**
- âœ“ Deliberate changes
- âœ“ Conservative releases  
- âœ“ Boring upgrades (in a good way)
- âœ“ No breaking changes without cause
- âœ“ Documentation that matches reality

---

## ğŸ¯ WHY THIS EXISTS

<div align="center">

### _Because local AI deserves tooling that respects:_

</div>

<table>
<tr>
<td align="center">ğŸ’¾<br><b>Limited VRAM</b></td>
<td align="center">ğŸ“<br><b>Limited Context</b></td>
<td align="center">ğŸ¤<br><b>User Trust</b></td>
<td align="center">ğŸŒ<br><b>Reality Itself</b></td>
</tr>
</table>

Most local AI frontends act like:
- VRAM is infinite
- Context windows are bottomless
- Silently failing is acceptable
- Users won't notice broken promises

**We refuse to pretend.**

openOrchestrate exists for people who want:
- Their AI to work predictably
- Their hardware to be respected
- Their data to stay local
- Their time to be valued

---

<div align="center">

## ğŸ´ó §ó ¢ó ·ó ¬ó ³ó ¿ MADE IN WALES

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Flag_of_Wales.svg/320px-Flag_of_Wales.svg.png" alt="Welsh Flag" width="200">

### _Crafted with love, discipline, and entirely too much tea._

</div>

---

<div align="center">

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                                                  â”ƒ
â”ƒ  "Finally, a local AI tool that doesn't         â”ƒ
â”ƒ   treat me like I have a datacenter"            â”ƒ
â”ƒ                                   â€” Hopefully Youâ”ƒ
â”ƒ                                                  â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
```

### ğŸ’¬ Got Questions? Found Bugs? Have Opinions?

**Issues are welcome. PRs are reviewed. Respect is expected.**

</div>

---

<div align="center">

![Powered by](https://img.shields.io/badge/powered_by-PRINCIPLES-blueviolet?style=for-the-badge)
![Built with](https://img.shields.io/badge/built_with-DISCIPLINE-orange?style=for-the-badge)
![Tested on](https://img.shields.io/badge/tested_on-REAL_HARDWARE-green?style=for-the-badge)

**[â¬†ï¸ BACK TO TOP](#)**

---

_Last Updated: 2026 | Page Views: âˆ | Caffeine Consumed: Yes_

</div>
